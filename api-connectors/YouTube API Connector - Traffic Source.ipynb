{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1420788",
   "metadata": {},
   "source": [
    "# YouTube API Connector - Traffic Source\n",
    "\n",
    "First of all, let's import the libraries to connect to the YouTube API and manipulate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ab8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import googleapiclient.errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f34de",
   "metadata": {},
   "source": [
    "Then, let's add the credentials to connect to the YouTube Data v3 API. This will provide us a generic information about the channel, including the ID of the playlist where all the videos are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581aaf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'youtube#channelListResponse', 'etag': 'xm0qCYcUUWM0F3XMlRFDWwej_n8', 'pageInfo': {'totalResults': 1, 'resultsPerPage': 5}, 'items': [{'kind': 'youtube#channel', 'etag': 'eyLQNm6fwyqFzcXjoobAzVEH-Cw', 'id': 'UCzQTrA_c1BgRNLewVyt2UFw', 'contentDetails': {'relatedPlaylists': {'likes': '', 'uploads': 'UUzQTrA_c1BgRNLewVyt2UFw'}}}]}\n"
     ]
    }
   ],
   "source": [
    "# Defining the API Key\n",
    "api_key = 'AIzaSyALPpP2k7wROgQwAKnlfoa3-idzf8mxSLE'\n",
    "\n",
    "# Defining the API name and version before connection\n",
    "youtube_api_service_name = \"youtube\"\n",
    "youtube_api_version = \"v3\"\n",
    "\n",
    "youtube = build(youtube_api_service_name, youtube_api_version, developerKey = api_key)\n",
    "\n",
    "# Gathering the channel content details\n",
    "request = youtube.channels().list(part='ContentDetails', id = 'UCzQTrA_c1BgRNLewVyt2UFw')\n",
    "\n",
    "response = request.execute()\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aba4ad",
   "metadata": {},
   "source": [
    "In the next step, this playlist ID will allow to provide us to get all the video IDs, the title, the description, and the publish date. I have created a function to gather all this data for this step.\n",
    "\n",
    "As it is only possible to get the data from only 50 videos, it is necessary to use the 'nextPageToken' to extract the data from the rest of the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75bddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding read permissions to the API\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "# Creating a function to gather all the video information from the previous playlistId\n",
    "def gather_youtube_videos(playlistId):\n",
    "\n",
    "    youtube = build(youtube_api_service_name, youtube_api_version, developerKey = api_key)\n",
    "    res = youtube.playlistItems().list(part=\"snippet\", playlistId='UUzQTrA_c1BgRNLewVyt2UFw', maxResults=\"50\").execute()\n",
    "\n",
    "    nextPageToken = res.get('nextPageToken')\n",
    "    \n",
    "    # Creating a while structure to gather the video from the rest of the pages. \n",
    "    #It will stop when there hare no more 'nextPageToken' available\n",
    "    while ('nextPageToken' in res):\n",
    "        nextPage = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId=playlistId,\n",
    "        maxResults=\"50\",\n",
    "        pageToken=nextPageToken\n",
    "        ).execute()\n",
    "        \n",
    "        res['items'] = res['items'] + nextPage['items']\n",
    "\n",
    "        if 'nextPageToken' not in nextPage:\n",
    "            res.pop('nextPageToken', None)\n",
    "        else:\n",
    "            nextPageToken = nextPage['nextPageToken']\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6646c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function over the PlayListId to gather the basic data from the videos\n",
    "info_videos = gather_youtube_videos('UUzQTrA_c1BgRNLewVyt2UFw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13356af",
   "metadata": {},
   "source": [
    "Let's extract the video IDs for each video from the previous dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48164fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the variables to store the data from the dictionary\n",
    "video_id = []\n",
    "\n",
    "# Gather all the video IDs from the dictionary\n",
    "for item in info_videos[\"items\"]:\n",
    "    video_id.append(item['snippet']['resourceId']['videoId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa2859",
   "metadata": {},
   "source": [
    "In the following step, I will gather views and the estimated minutes watched on a daily basis and store it on a dictionary per traffic source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95677191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=852632511285-09e8025vv77tqnorhjgp8lof8j6j67cm.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.readonly&state=C2jTUOvOJGsJfMKHFumSj8duXYMAJa&prompt=consent&access_type=offline\n",
      "Enter the authorization code: 4/1ARtbsJrZpWdFHswwTYZ_PmxTpnW2dAL1OBqO7i3f-unXs_n-wucJoxZj5HQ\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary to store the data\n",
    "dic = {}\n",
    "\n",
    "# Creating a function to gather the data\n",
    "def main():\n",
    "    \n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "    api_service_name = \"youtubeAnalytics\"\n",
    "    api_version = \"v2\"\n",
    "    client_secrets_file = \"superclient.json\"\n",
    "\n",
    "    # Get credentials and create API client\n",
    "    flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "        client_secrets_file, scopes)\n",
    "    credentials = flow.run_console()\n",
    "    youtube_analytics = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, credentials=credentials)\n",
    "\n",
    "    # Get the metrics for each video\n",
    "    \n",
    "    request1 = youtube_analytics.reports().query(\n",
    "    dimensions=\"day,insightTrafficSourceType\",\n",
    "    endDate='2022-10-10',\n",
    "    ids=\"channel==MINE\",\n",
    "    metrics=\"views,estimatedMinutesWatched\",\n",
    "    startDate=\"2021-03-08\"\n",
    "    )\n",
    "    response2 = request1.execute()\n",
    "\n",
    "    dic['remove'] = response2['rows']\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af63c13",
   "metadata": {},
   "source": [
    "Now, all the data gathered has been stored in a dictionary. Let's transform that dictionary into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844b5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the variables extracted from each video\n",
    "video_metrics = ['date', 'traffic_source', 'views','estimatedMinutesWatched']\n",
    "\n",
    "# Use the .items() method to store the key and the values separately in the DataFrame\n",
    "df_metrics = pd.DataFrame(dic.items())\n",
    "df_metrics\n",
    "\n",
    "# Removing the column 0\n",
    "#df_metrics.drop(0, axis = 1, inplace = True)\n",
    "\n",
    "# Renaming the columns\n",
    "df_metrics.rename(columns={1: 'metrics'}, inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4523e7",
   "metadata": {},
   "source": [
    "I will use the function .explode() in the next step to transform each element of a list-like to a row, replicating the index values. That's why I will a reset_index() function at the end of the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80a49300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2021-03-08, NO_LINK_OTHER, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2021-03-08, ADVERTISING, 18, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2021-03-08, SUBSCRIBER, 7, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2021-03-08, YT_CHANNEL, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2021-03-08, YT_SEARCH, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2022-10-10, YT_SEARCH, 68, 188]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2022-10-10, RELATED_VIDEO, 9, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2022-10-10, EXT_URL, 7, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2022-10-10, PLAYLIST, 2, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>remove</td>\n",
       "      <td>[2022-10-10, YT_PLAYLIST_PAGE, 2, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4879 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                               metrics\n",
       "0     remove     [2021-03-08, NO_LINK_OTHER, 0, 0]\n",
       "1     remove      [2021-03-08, ADVERTISING, 18, 3]\n",
       "2     remove       [2021-03-08, SUBSCRIBER, 7, 11]\n",
       "3     remove        [2021-03-08, YT_CHANNEL, 4, 7]\n",
       "4     remove         [2021-03-08, YT_SEARCH, 1, 0]\n",
       "...      ...                                   ...\n",
       "4874  remove      [2022-10-10, YT_SEARCH, 68, 188]\n",
       "4875  remove    [2022-10-10, RELATED_VIDEO, 9, 41]\n",
       "4876  remove          [2022-10-10, EXT_URL, 7, 25]\n",
       "4877  remove         [2022-10-10, PLAYLIST, 2, 12]\n",
       "4878  remove  [2022-10-10, YT_PLAYLIST_PAGE, 2, 5]\n",
       "\n",
       "[4879 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .explode() function to desaggregate the lists on the metrics columns\n",
    "df_stacked = df_metrics.explode('metrics').reset_index(drop=True)\n",
    "df_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0437b02",
   "metadata": {},
   "source": [
    "Now, let's do some final transformations before exporting this DataFrame to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab42b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xsof\\AppData\\Local\\Temp\\ipykernel_8812\\3231103768.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_stacked['metrics'] = df_stacked['metrics'].str.replace('[', '')\n",
      "C:\\Users\\xsof\\AppData\\Local\\Temp\\ipykernel_8812\\3231103768.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_stacked['metrics'] = df_stacked['metrics'].str.replace(']', '')\n"
     ]
    }
   ],
   "source": [
    "# Changing the metrics variable as string to do some replacements\n",
    "df_stacked['metrics'] = df_stacked['metrics'].astype(str)\n",
    "\n",
    "# Replace the brackers by nothing\n",
    "df_stacked['metrics'] = df_stacked['metrics'].str.replace('[', '')\n",
    "df_stacked['metrics'] = df_stacked['metrics'].str.replace(']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6024ffb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>traffic_source</th>\n",
       "      <th>views</th>\n",
       "      <th>estimatedMinutesWatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>NO_LINK_OTHER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>ADVERTISING</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>SUBSCRIBER</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>YT_CHANNEL</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>YT_SEARCH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>YT_SEARCH</td>\n",
       "      <td>68</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>RELATED_VIDEO</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>EXT_URL</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>PLAYLIST</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>YT_PLAYLIST_PAGE</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4879 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     traffic_source views estimatedMinutesWatched\n",
       "0     2021-03-08      NO_LINK_OTHER     0                       0\n",
       "1     2021-03-08        ADVERTISING    18                       3\n",
       "2     2021-03-08         SUBSCRIBER     7                      11\n",
       "3     2021-03-08         YT_CHANNEL     4                       7\n",
       "4     2021-03-08          YT_SEARCH     1                       0\n",
       "...          ...                ...   ...                     ...\n",
       "4874  2022-10-10          YT_SEARCH    68                     188\n",
       "4875  2022-10-10      RELATED_VIDEO     9                      41\n",
       "4876  2022-10-10            EXT_URL     7                      25\n",
       "4877  2022-10-10           PLAYLIST     2                      12\n",
       "4878  2022-10-10   YT_PLAYLIST_PAGE     2                       5\n",
       "\n",
       "[4879 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the metrics columns into several columns\n",
    "df_stacked[video_metrics] = df_stacked['metrics'].str.split(',', expand = True)\n",
    "df_stacked.drop(['metrics', 0], axis = 1, inplace = True)\n",
    "df_stacked['date'] = df_stacked['date'].str.replace(\"'\", '')\n",
    "df_stacked['traffic_source'] = df_stacked['traffic_source'].str.replace(\"'\", '')\n",
    "df_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9741991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CSV file\n",
    "df_stacked.to_csv('traffic_source_performance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2e1ec",
   "metadata": {},
   "source": [
    "In the following steps, I will connect to Google BigQuery with two different goals:\n",
    "\n",
    "1. Create a table to store the data recently extracted\n",
    "2. Pull the output file got in the previous step to that Google BigQuery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ba0eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to connect with Google BigQuery\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Adding the credentials from the JSON file to connect with the platform\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "'misuperproyecto-06012a0c4865.json')\n",
    "project_id = 'misuperproyecto'\n",
    "client = bigquery.Client(credentials= credentials, project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac869d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table misuperproyecto.youtube_channel_data.fact_trafficsource_performance\n"
     ]
    }
   ],
   "source": [
    "# Set table_id to the ID of the table to create\n",
    "table_id = 'misuperproyecto.youtube_channel_data.fact_trafficsource_performance'\n",
    "\n",
    "# Add the schema of the table\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"date\", \"DATE\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"traffic_source\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"views\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"estimatedMinutesWatched\", \"INTEGER\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "# Make an API request to create the table\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)  \n",
    "print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354208b6",
   "metadata": {},
   "source": [
    "Finally, let's push the .csv() file created to Google BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f642fafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4879 rows and 4 columns to misuperproyecto.youtube_channel_data.fact_trafficsource_performance\n"
     ]
    }
   ],
   "source": [
    "# Specify the name of the file\n",
    "file_path = 'traffic_source_performance.csv'\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True,\n",
    ")\n",
    "\n",
    "# Open and read the file\n",
    "with open(file_path, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
    "job.result() \n",
    "\n",
    "# Make an API request to upload the table\n",
    "table = client.get_table(table_id)  \n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
